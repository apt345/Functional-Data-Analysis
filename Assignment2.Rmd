---
title: "Assignment 2 Functional Data Analysis"
author: "Arturo Prieto Tirado"
date: "10/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```



## Exercise 2

The gait data set is included in the fda package. Therefore, you can load the data set after loading the library fda, using data(gait). The object gait is an array of size 20x39x2 containing the hip and knee angle in degrees through a 20 point movement cycle for 39 boys. Carry out the following tasks and write a report summarizing your work:
```{r}
library(fda)
data(gait)
color_1 <- "deepskyblue2"
color_2 <- "darkorange2"
color_3 <- "darkorchid2"

# hip angles are :,:, 1

x=as.numeric(row.names(gait))

```


- (a) Compute all the sample characteristics described in Topic 2 for the hip angles and obtain conclusions from the analysis.

### Preliminar steps

We work again with the same dataset as in the assignment 1. The following plot shows the distribution of the hip angles for the 39 boys just by interpolating the points.

```{r }
color_1 <- "deepskyblue2"
color_2 <- "darkorange2"
color_3 <- "darkorchid2"
color_4 <- "chartreuse2"
color_5 <- "firebrick2"
interval=c(0,1)
matplot(x=x, y=gait[, , 1],type="l",lty=1,col=color_1,
        xlab="Movement Cycle",ylab="Hip Angle (degrees)",main="Hip angles")
```

It can be seen that most of the children follow the same shape, high angles at the beggining and end of the cycle and low angles in the middle. However, some of them follow curves far away from the group, with the possibility of being outliers. Also, the curves are obviously not smooth since we are just joining lines so the next step is to smooth them.

### Smoothing the hip angles

The first step is to obtain functions from our data, smooth them. This was done in the first assignment. We just repeat the procedure here.  I will use 7 Fourier basis with a penalization algorithm as in the previous assignment. This is done using the function `create.fourier.basis` and then fitting the basis to the data with the penalization algorithm. The observation interval is $[0,1]$, with the extremes being the two points corresponding to a full period (cycle) that determine the periodicity of the function.

The following plot shows the optimal penalization parameter $\lambda$ (the same as in the first assignment) obtained by Generalized Cross Validation.

```{r }
fourier_basis_7 <- create.fourier.basis(rangeval=interval,nbasis=7)
lambdas <- seq(1e-6,2e-5,by=1e-6)
#head(lambdas)
l_lambdas <- length(lambdas)
#l_lambdas
gcv_lambdas <- vector(mode="numeric",length=l_lambdas)
for (i in 1:l_lambdas){
  Fourier_pen_7 <- fdPar(fdobj=fourier_basis_7,Lfdobj=2,lambda=lambdas[i])
  smooth_dailyAv_temp_7_pen <-smooth.basis(argvals=x,y=gait[,,1],
                                            fdParobj=Fourier_pen_7)
  #the value of GCV is the sum of the individual ones
  gcv_lambdas[i] <- sum(smooth_dailyAv_temp_7_pen$gcv)
}
plot(lambdas,gcv_lambdas,pch=19,col=color_1,main="GCV criterion for lambdas",
     xlab="Lambda values",ylab="Value of GCV")
#lambdas[which.min(gcv_lambdas)]
```

Then, we proceed to make the fit with such value of $\lambda=1.4\cdot10^{-5}$ for the $39$ children to transform our data into functions. The smoothed results are shown in the following plot.

```{r }
Fourier_pen_7 <- fdPar(fdobj=fourier_basis_7,Lfdobj=2,lambda=lambdas[which.min(gcv_lambdas)])
smooth_dailyAv_temp_7_pen <- smooth.basis(argvals=x,y=gait[,,1],
                                           fdParobj=Fourier_pen_7)
plot(smooth_dailyAv_temp_7_pen,xlab="Cycle",ylab="Hip Angle (degrees)")
title("Smoothed Hip Angle with roughness penalty with 7 Fourier basis")
lines(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,col=color_1)
```

### Sample functional mean

Next, we compute the **sample functional mean** of the smoothed data set and add the resulting function into the previous plot. We can see that the functional mean reflects in general quite well the center of the functions.

```{r }
mean_temp <- mean.fd(smooth_dailyAv_temp_7_pen$fd)
plot(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,xlab="Movement Cycle",ylab="Hip Angle (degrees)")
title("Smoothed hip angles and sample functional mean")
lines(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,col=color_1)
lines(mean_temp,col=color_2,lwd=3)
```

### Sample functional standard deviation

Now, we compute the **sample functional standard deviation** of the smoothed data set before having a look to the sample functional covariance that includes the sample functional variance. We add the resulting function into the plot with the $39$ functions. We can see that the functional standard deviation shows that the variability is almost constant throughout the cycle, with slightly more variability at the beginning and end of the cycle and less in the middle.

```{r }
sd_temp <- sd.fd(smooth_dailyAv_temp_7_pen$fd)
plot(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,xlab="Movement Cycle",ylab="Hip Angle")
title("Smoothed hip angles and sample functional standard deviation")
lines(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,col=color_1)
lines(sd_temp,col=color_2,lwd=3)
```

### Sample functional covariance (including variance)

The next step is to obtain the **sample covariance function** of the smoothed data set that includes in particular the functional variance. The best way to analyze the sample covariance is through a contour plot and the perspective plot. For that, we need to evaluate the sample covariance function obtained at a set of evaluation points. For instance, we can take $50$ points. We can see several aspects: (1) the sample functional variance results in considering $t=s$. Of course, the behavior is similar to the one from the functional standard deviation, i.e., the variability is almost constant throughout the cycle, with slightly more variability at the beginning and end of the cycle and less in the middle, but since the $t=s$ shows the variance, which is the squared of the standard deviation, it is easier to see the differences between extremes and the middle of the cycle. (2) the sample covariance between nearby points is larger also in extremes of the cycle than in middle points.

```{r }
cov_temp <- var.fd(smooth_dailyAv_temp_7_pen$fd)
points_temp <- seq(0,1,length.out=20)
cov_points_temp <- eval.bifd(points_temp,points_temp,cov_temp)
persp(points_temp,points_temp,cov_points_temp,phi=30,theta=30,expand=.5,col=color_1,
      ltheta=120,shade=0.5,ticktype="detailed",xlab="t",ylab="s",zlab="",
      r=40,d=.1,border=color_3,main="Covariance function of the hip angles of gait data set")
contour(points_temp,points_temp,cov_points_temp,lwd=2,
        main="Contour plot of the covariance function of the hip angles of gait data set",col=color_1)
```

- Carry out a functional principal component analysis of the of the hip angles and
obtain conclusions from the analysis. 

### Sample functional PCA

Here, we are going to obtain the **sample functional principal components** corresponding to the smoothed ahip angles. In this way, we are going to obtain the primary modes of variation of the data and how many of them are important. For that, we will use the function `pca.fd` of the `fda` package. In particular, `nharm` is the number of FPCs that we want to obtain, in this case, 5 seems more than enough.

```{r }
pcs_temp <- pca.fd(smooth_dailyAv_temp_7_pen$fd,nharm=5,harmfdPar=fdPar(smooth_dailyAv_temp_7_pen$fd))
#names(pcs_temp)
```

We start by having a look at the eigenvalues that will help us to decide how many FPCs are important. For that we define a table that includes the eigenvalues and the proportion of variability explained by the FPCs:

```{r }
table_fpcs_temp <- cbind(pcs_temp$values[1:5],pcs_temp$varprop,cumsum(pcs_temp$varprop))
table_fpcs_temp
par(mfrow=c(1,2))
plot(1:5,table_fpcs_temp[,1],pch=19,col=color_1,type="b",main="Sample eigenvalues",
     xlab="Number of eigenvalue",ylab="Value")
plot(1:5,table_fpcs_temp[,2],pch=19,col=color_1,type="b",main="Proportion of variability",
     xlab="Number of eigenvalue",ylab="Value")
```

From the table, we can see that only $2$ FPCs are able to explain the $85%$ of the total variability. Therefore, we recompute the FPCs asking for only two for plotting them.

```{r }
npc=2
pcs_temp <- pca.fd(smooth_dailyAv_temp_7_pen$fd,nharm=npc,harmfdPar=fdPar(smooth_dailyAv_temp_7_pen$fd))
par(mfrow=c(1,2))
plot(pcs_temp$harmonics[1],lty=1,lwd=2,xlab="Days",ylab="Value")
title("First FPC")
lines(pcs_temp$harmonics[1],lty=1,lwd=2,col=color_1)
plot(pcs_temp$harmonics[2],lty=1,lwd=2,xlab="Days",ylab="Value")
title("Second FPC")
lines(pcs_temp$harmonics[2],lty=1,lwd=2,col=color_1)
```

We can see that the first FPC clearly show something expected. The variability is larger in beginning and end of the cycle and less on the middle points. On the other hand, the second FPC shows a contrast between the first half and the second half of the cycle. Therefore, there two main sources of variation in the data set. On the one hand, the different variability among extremes and middle values and the differences between first half and second half.

Next, we can plot the functional principal component scores (FPCs). We can see that the scores show the presence of groups and probably outliers as Boy 5 or Boy 38.

```{r }
plot(pcs_temp$scores,pch=19,col=color_1,main="FPCs scores",xlab="First score",ylab="Second score")
text(pcs_temp$scores,labels=paste("Boy",1:39),pos=1,col=color_5,cex=0.7)
#number the different boys from 1 to 39
```

- Compute the functional data depths for the hip angles and obtain conclusions from the analysis. How big does the influence of the most extreme curves seem to be?

### Functional depths

Here, we are going to compute **functional depths** for the smoothed data. For that, we will make use of the `fda.usc` package. It is important to note that the way in which this package creates and smooth functional data sets is different than the way with the `fda` package. Therefore, it is necessary to be careful in the following steps.

Then, we start by loading the `fda.usc` package and by creating a functional object using the `fdata` function of this package.

```{r }
library(fda.usc)
tt <- x
Canadian_temp_smooth <- eval.fd(tt,smooth_dailyAv_temp_7_pen$fd)
fdataobj_temp <- fdata(t(Canadian_temp_smooth),tt)
```

The idea with depths is to make an ordering of the most central function (the deepest one) and the least central function (the one with the lowest depth).


Next, we compute the value of the **Fraiman and Muniz depth** with the function `depth.FM`. Note that we add the option `draw=TRUE` to get a plot of the functions where the most central function appears in red, the most central function if a certain proportion of functions is trimmed appears in blue, and the others appear in a gray scale, where dark gray means very central, and soft gray means very extreme. Additionally, we plot the value of the depths for the $39$ boys. We can see that **Boy 22 is the most central, while Boy 23 is the most extreme**.

```{r }
depth_FM_Canadian <- depth.FM(fdataobj_temp,trim=.1,draw=TRUE)
plot(1:39,depth_FM_Canadian$dep,col=color_1,pch=19,
     ylim=c(min(depth_FM_Canadian$dep)-0.1,max(depth_FM_Canadian$dep)+0.1),
     xlab="Weather station",ylab="Value of the depth",main="Fraiman and Muniz depth for hip angles")
text(1:39,depth_FM_Canadian$dep,labels=paste("Boy",1:39),pos=1,col=color_2,cex=0.7)
```

Next, we compute the value of the **modal depth** with the function `depth.mode`. In this case, we can see that **Boy 22 is the most central again, while Boy 5 is the most extreme**. Note that the most extreme function is different than in the previous one while the most central is the same.

```{r }
depth_mode_Canadian <- depth.mode(fdataobj_temp,trim=.1,draw=TRUE)
plot(1:39,depth_mode_Canadian$dep,col=color_1,pch=19,
     ylim=c(min(depth_mode_Canadian$dep)-0.5,max(depth_mode_Canadian$dep)+0.5),
     xlab="Weather station",ylab="Value of the depth",main="Modal depth for hip angles")
text(1:39,depth_mode_Canadian$dep,labels=paste("Boy",1:39),pos=1,col=color_2,cex=0.7)
```

Now, we compute the value of the **random projection depth** with the function `depth.RP`. In this case, as there is a source of randomness in the computation of the depths, we can have a different ordering of the functions. We use $50$ projections and **Boy 22 appears to be the most central function while Boy 5, the most extreme**. 

```{r }
depth_RP_Canadian <- depth.RP(fdataobj_temp,nproj=50,trim=.1,draw=TRUE)
plot(1:39,depth_RP_Canadian$dep,col=color_1,pch=19,
     ylim=c(min(depth_RP_Canadian$dep)-0.05,max(depth_RP_Canadian$dep)+0.05),
     xlab="Weather station",ylab="Value of the depth",main="Random projections depth for hip angles")
text(1:39,depth_RP_Canadian$dep,labels=paste("Boy",1:39),pos=1,col=color_2,cex=0.7)
```

The last depth is the **functional spatial depth**. In this case, again **Boy 22 is the most central one and Boy 5 is the most extreme function**.

```{r }
depth_FSD_Canadian <- depth.FSD(fdataobj_temp,trim=.1,draw=TRUE)
plot(1:39,depth_FSD_Canadian$dep,col=color_1,pch=19,
     ylim=c(min(depth_FSD_Canadian$dep)-0.05,max(depth_FSD_Canadian$dep)+0.05),
     xlab="Weather station",ylab="Value of the depth",main="Functional spatial depth for temperatures")
text(1:39,depth_FSD_Canadian$dep,labels=paste("Boy",1:39),pos=1,col=color_2,cex=0.7)
```

Finally, we compare the value of all the depths in a scatterplot matrix. We can see that the values of the random projection depths and the functional spatial depths are very close. Anyway, note that all the relationships between depths appear to be linear except for Modal Depth and Spatial Depth, where some kind of curvature can be seen. Probably, the Fraiman and Muniz depth provides with the most different depth values.

```{r }
all_depths <- cbind(depth_FM_Canadian$dep,depth_mode_Canadian$dep,
                    depth_RP_Canadian$dep,depth_FSD_Canadian$dep)
colnames(all_depths) <- c("FM depth","Modal depth","RP depth","Spatial depth")
pairs(all_depths,col=color_1,pch=19)
```

- Apply the procedures for functional outlier detection for the hip angles and try to determine why the curves obtained as outliers, if any, appear to be outliers.

# Outlier detection with functional depths

Here, we are going to check whether there are **functional outliers** in the smoothed hip angles for each movement position in the Gait data set. For that, we will make use again of the `fda.usc` package that has implemented the **procedure for detecting outliers with functional depth with both the trimming and the weighting bootstrap methods to compute the cutoff $C$**. The functions are `outliers.depth.trim` and `outliers.depth.pond`, respectively. We are going to choose the default options, i.e., the number of bootstrap samples is $200$, the smoothing parameter $\gamma$ is $0.05$ and the functional depth used if the modal one. Also, for trimming, it is used $\alpha=0.01$.

```{r }
out_trimming <- outliers.depth.trim(fdataobj_temp)
#out_trimming
out_weighting <- outliers.depth.pond(fdataobj_temp)
#out_weighting
```

As it can be seen, the two procedures label the hip angles of Boy 5 as a functional outlier. This is not a surprise in view of the previous analysis. The estimates of the cutoff $C$ with trimming and weighting are $1.0392$ and $0.8802$, respectively, while the value of the depth at Boy 5 is $0.8186$. Finally, we make a plot of the data set and the detected functional outlier:

```{r }
plot(smooth_dailyAv_temp_7_pen,lty=1,lwd=2,col=color_1,
     xlab="Movement Cycle",ylab="Hip Angle (degrees)")
title("Smoothed Hip Angles and the outlier at Boy5")
lines(smooth_dailyAv_temp_7_pen[[1]],col=color_1,lty=1,lwd=2)
lines(smooth_dailyAv_temp_7_pen[[1]][5],col=color_2,lty=1,lwd=2)
```


## Exercise 4

Given a functional data set $y_i (t_{ij})$, where $t_{ij} \in [a, b]$, for $i = 1, \ldots, n$ and $j = 1, \ldots,  J_i$, obtain expressions of the modal and the functional spatial depths in terms of the basis system expansions of the observed curves. More precisely, for the modal depth, use the truncated Gaussian kernel.

### Modal depth

Idea: The most central curve should be the function most densely surrounded
by the rest of functions.

$$
M D_{n}\left(x_{i}\right)=\sum_{l=1}^{n} K\left(\frac{\left\|x_{i}-x_{l}\right\|}{h}\right)
$$
$K: \mathbb{R}^{+} \rightarrow \mathbb{R}^{+}$ is a kernel function, e.g., the truncated Gaussian kernel:
$$
K(t)=\sqrt{\frac{2}{\pi}} \exp \left(-\frac{t^{2}}{2}\right) \quad t>0
$$
$h$ is a bandwidth, e.g., the 15 -th quantile of the ECDF of the set of values $\left\{\left\|x_{i}-x_{l}\right\|: i, l=1, \ldots, n\right\}$

Since $x=\sum_i^w c_i e_i, w<n$, then

$$
M D_{n}\left(x_{i}\right)=\sum_{l=1}^{n} K\left(\frac{\left\|\sum_{j=1}^n c_{ij}e_{ij}-c_{lj}e_{lj}\right\|}{h}\right)
$$

and since the exponential of the sum is the product of exponentials:

$$
M D_{n}\left(x_{i}\right)=\sum_{l=1}^{n} \prod_{j=1}^n \exp \Big(\frac{\left\| c_{ij}e_{ij}-c_{lj}e_{lj}\right\|}{h}\Big)
$$


### Functional Spatial Depth



- The sign function: For $x \in \mathbb{R}$
$$
S(x)=\left\{\begin{array}{cl}
\frac{x}{|x|} & \text { if } x \neq 0 \\
0 & \text { if } x=0
\end{array}=\left\{\begin{array}{cl}
1 & \text { if } x>0 \\
0 & \text { if } x=0 \\
-1 & \text { if } x<0
\end{array}\right.\right.
$$
- Consider: A sample $x_{1}, \ldots, x_{n}$ from a real random variable $X$.
- Let: $x_{(1)}, \ldots, x_{(n)}$ be the ordered sample.
ÑŒ Then:
$\sum_{i=1}^{n} S\left(x_{(1)}-x_{i}\right)=-(n-1) .$
$\sum_{i=1}^{n} S\left(x_{m e d}-x_{i}\right)=0$
$\sum_{i=1}^{n} S\left(x_{(n)}-x_{i}\right)=n-1$
$ Spatial depth: S D\left(x_{i}\right)=1-\frac{1}{n-1}\left|\sum_{l=1}^{n} S\left(x_{i}-x_{l}\right)\right| .$






